ğŸš˜ ParkScope â€“ AI-Based Parking Difficulty Prediction
â­ Project Motivation

Finding street parking in dense urban areas often results in long search times, increased congestion, wasted fuel, and driver frustration.
Despite advanced navigation tools, no existing system (Waze, Google Maps) provides a real-time estimation of how difficult it will be to find parking near your destination.

ParkScope introduces an AI-driven parking difficulty estimator designed to enhance navigation and reduce unnecessary driving loops.

ğŸ¯ Problem Statement

Predict a Parking Difficulty Score (1â€“10) from a single street-level image, indicating how likely it is to find an available parking spot in that area.

1 â†’ very easy to park
10 â†’ extremely difficult

ğŸ§© Visual Abstract

(Insert pipeline_diagram.png here)
A high-level overview of the detection, feature extraction, and regression components used to generate the difficulty score.

ğŸ“š Dataset

ParkScope uses a combination of real, synthetic, and auto-labeled data:

Real street images
From datasets like Cityscapes and BDD100K.

Synthetic images
Generated with Stable Diffusion to create scenes with varying densities, lighting, weather, and street layouts.

Auto-generated labels
Using parking density heuristics derived from object detection & curb segmentation.

Numerical features

car_count

curb_length

density_ratio

Additional contextual features extracted from segmentation.

ğŸ”§ Data Augmentation & Generation

To improve robustness and expand the dataset:

Synthetic variations: crowded vs. empty streets

Time-of-day changes: morning, afternoon, night

Weather simulation: rain, fog, low visibility

Image augmentations: brightness, contrast, blur, shadows

Labeling Pipeline:
YOLO/DETR (car detection) â†’ curb segmentation â†’ density calculation â†’ difficulty score

ğŸ§  Models & Pipelines
1. Detection Layer

YOLO/DETR for identifying parked vehicles and extracting bounding boxes.

2. Segmentation Layer

Curb and road segmentation to estimate available parking space.

3. Feature Computation

Density ratio = number_of_cars / curb_length

4. Regression Models

XGBoost Regressor (baseline for numeric features)

ResNet50 (fine-tuned vision regression model)

Vision Transformer (ViT-B/16) (state-of-the-art deep learning model)

ğŸ‹ï¸ Training Process

Train XGBoost baseline using extracted features.

Fine-tune ResNet50 and ViT on full images.

Compare model performance across the same validation/test sets.

Tune hyperparameters and experiment with augmentation strategies.

Evaluate and refine density-based labeling heuristics.

ğŸ“ Metrics

Models are evaluated using:

MAE â€“ Mean Absolute Error

RMSE â€“ Root Mean Square Error

Difficulty Category Accuracy (easy / medium / hard)

Pearson Correlation between prediction and true density

ğŸ“ˆ Results

(Insert plots, tables, and visualizations here.)
Examples include:

Comparison charts of model performance

Error distribution graphs

Qualitative examples of predicted scores vs. ground truth

ğŸ“ Repository Structure

(Insert the structure you approved earlier.)

ğŸ‘¤ Team Members

Lior Yanwo
